{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Digit Recognizer - Baseline Solution\n",
    "\n",
    "**Kaggle Competition**: [Digit Recognizer](https://www.kaggle.com/competitions/digit-recognizer)\n",
    "\n",
    "ÐšÐ»Ð°ÑÑÐ¸Ñ„Ð¸ÐºÐ°Ñ†Ð¸Ñ Ñ€ÑƒÐºÐ¾Ð¿Ð¸ÑÐ½Ñ‹Ñ… Ñ†Ð¸Ñ„Ñ€ MNIST Ñ Ð¸ÑÐ¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ð½Ð¸ÐµÐ¼ CNN (PyTorch)\n",
    "\n",
    "## Ð¡Ð¾Ð´ÐµÑ€Ð¶Ð°Ð½Ð¸Ðµ\n",
    "1. Ð—Ð°Ð³Ñ€ÑƒÐ·ÐºÐ° Ð¸ Ð¸ÑÑÐ»ÐµÐ´Ð¾Ð²Ð°Ð½Ð¸Ðµ Ð´Ð°Ð½Ð½Ñ‹Ñ…\n",
    "2. ÐŸÑ€ÐµÐ´Ð¾Ð±Ñ€Ð°Ð±Ð¾Ñ‚ÐºÐ° Ð´Ð°Ð½Ð½Ñ‹Ñ…\n",
    "3. ÐŸÐ¾ÑÑ‚Ñ€Ð¾ÐµÐ½Ð¸Ðµ CNN Ð¼Ð¾Ð´ÐµÐ»Ð¸\n",
    "4. ÐžÐ±ÑƒÑ‡ÐµÐ½Ð¸Ðµ\n",
    "5. ÐŸÑ€ÐµÐ´ÑÐºÐ°Ð·Ð°Ð½Ð¸Ñ Ð¸ submission"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Ð˜Ð¼Ð¿Ð¾Ñ€Ñ‚Ñ‹ Ð¸ Ð½Ð°ÑÑ‚Ñ€Ð¾Ð¹ÐºÐ¸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-02T19:51:39.074477Z",
     "start_time": "2026-01-02T19:51:34.187806Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset, random_split\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# ÐÐ°ÑÑ‚Ñ€Ð¾Ð¹ÐºÐ¸\n",
    "RANDOM_SEED = 42\n",
    "BATCH_SIZE = 64\n",
    "EPOCHS = 15\n",
    "LEARNING_RATE = 0.001\n",
    "\n",
    "# Ð£ÑÑ‚Ñ€Ð¾Ð¹ÑÑ‚Ð²Ð¾\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'Ð£ÑÑ‚Ñ€Ð¾Ð¹ÑÑ‚Ð²Ð¾: {device}')\n",
    "\n",
    "np.random.seed(RANDOM_SEED)\n",
    "torch.manual_seed(RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Ð—Ð°Ð³Ñ€ÑƒÐ·ÐºÐ° Ð´Ð°Ð½Ð½Ñ‹Ñ…"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-02T19:52:37.444452Z",
     "start_time": "2026-01-02T19:52:33.399667Z"
    }
   },
   "outputs": [],
   "source": [
    "# ÐŸÑƒÑ‚ÑŒ Ðº Ð´Ð°Ð½Ð½Ñ‹Ð¼ (Ð´Ð»Ñ Kaggle Kernel)\n",
    "train_df = pd.read_csv('data/train.csv')\n",
    "test_df = pd.read_csv('data/test.csv')\n",
    "\n",
    "print(f'Train shape: {train_df.shape}')\n",
    "print(f'Test shape: {test_df.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-02T19:52:42.750565Z",
     "start_time": "2026-01-02T19:52:42.721701Z"
    }
   },
   "outputs": [],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Ð˜ÑÑÐ»ÐµÐ´Ð¾Ð²Ð°Ð½Ð¸Ðµ Ð´Ð°Ð½Ð½Ñ‹Ñ… (EDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-02T19:52:52.901626Z",
     "start_time": "2026-01-02T19:52:51.941180Z"
    }
   },
   "outputs": [],
   "source": [
    "# Ð Ð°ÑÐ¿Ñ€ÐµÐ´ÐµÐ»ÐµÐ½Ð¸Ðµ ÐºÐ»Ð°ÑÑÐ¾Ð²\n",
    "plt.figure(figsize=(10, 5))\n",
    "sns.countplot(x='label', data=train_df, palette='viridis')\n",
    "plt.title('Ð Ð°ÑÐ¿Ñ€ÐµÐ´ÐµÐ»ÐµÐ½Ð¸Ðµ Ñ†Ð¸Ñ„Ñ€ Ð² Ð¾Ð±ÑƒÑ‡Ð°ÑŽÑ‰ÐµÐ¹ Ð²Ñ‹Ð±Ð¾Ñ€ÐºÐµ')\n",
    "plt.xlabel('Ð¦Ð¸Ñ„Ñ€Ð°')\n",
    "plt.ylabel('ÐšÐ¾Ð»Ð¸Ñ‡ÐµÑÑ‚Ð²Ð¾')\n",
    "plt.show()\n",
    "\n",
    "print('Ð Ð°ÑÐ¿Ñ€ÐµÐ´ÐµÐ»ÐµÐ½Ð¸Ðµ ÐºÐ»Ð°ÑÑÐ¾Ð²:')\n",
    "print(train_df['label'].value_counts().sort_index())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-02T19:53:01.693926Z",
     "start_time": "2026-01-02T19:53:00.780719Z"
    }
   },
   "outputs": [],
   "source": [
    "# Ð’Ð¸Ð·ÑƒÐ°Ð»Ð¸Ð·Ð°Ñ†Ð¸Ñ Ð¿Ñ€Ð¸Ð¼ÐµÑ€Ð¾Ð²\n",
    "fig, axes = plt.subplots(2, 5, figsize=(12, 5))\n",
    "\n",
    "for digit in range(10):\n",
    "    ax = axes[digit // 5, digit % 5]\n",
    "    sample = train_df[train_df['label'] == digit].iloc[0, 1:].values\n",
    "    ax.imshow(sample.reshape(28, 28), cmap='gray')\n",
    "    ax.set_title(f'Ð¦Ð¸Ñ„Ñ€Ð°: {digit}')\n",
    "    ax.axis('off')\n",
    "\n",
    "plt.suptitle('ÐŸÑ€Ð¸Ð¼ÐµÑ€Ñ‹ ÐºÐ°Ð¶Ð´Ð¾Ð¹ Ñ†Ð¸Ñ„Ñ€Ñ‹', fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-02T19:53:14.198682Z",
     "start_time": "2026-01-02T19:53:13.499521Z"
    }
   },
   "outputs": [],
   "source": [
    "# Ð¡Ð»ÑƒÑ‡Ð°Ð¹Ð½Ñ‹Ðµ Ð¿Ñ€Ð¸Ð¼ÐµÑ€Ñ‹\n",
    "fig, axes = plt.subplots(3, 5, figsize=(12, 7))\n",
    "\n",
    "random_indices = np.random.choice(len(train_df), 15, replace=False)\n",
    "\n",
    "for idx, ax in zip(random_indices, axes.flatten()):\n",
    "    image = train_df.iloc[idx, 1:].values.reshape(28, 28)\n",
    "    label = train_df.iloc[idx, 0]\n",
    "    ax.imshow(image, cmap='gray')\n",
    "    ax.set_title(f'Label: {label}')\n",
    "    ax.axis('off')\n",
    "\n",
    "plt.suptitle('Ð¡Ð»ÑƒÑ‡Ð°Ð¹Ð½Ñ‹Ðµ Ð¿Ñ€Ð¸Ð¼ÐµÑ€Ñ‹ Ð¸Ð· Ð¾Ð±ÑƒÑ‡Ð°ÑŽÑ‰ÐµÐ¹ Ð²Ñ‹Ð±Ð¾Ñ€ÐºÐ¸', fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. ÐŸÑ€ÐµÐ´Ð¾Ð±Ñ€Ð°Ð±Ð¾Ñ‚ÐºÐ° Ð´Ð°Ð½Ð½Ñ‹Ñ…"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-02T19:53:24.746883Z",
     "start_time": "2026-01-02T19:53:23.394193Z"
    }
   },
   "outputs": [],
   "source": [
    "# Ð Ð°Ð·Ð´ÐµÐ»ÐµÐ½Ð¸Ðµ Ð½Ð° Ð¿Ñ€Ð¸Ð·Ð½Ð°ÐºÐ¸ Ð¸ Ð¼ÐµÑ‚ÐºÐ¸\n",
    "X = train_df.drop('label', axis=1).values\n",
    "y = train_df['label'].values\n",
    "\n",
    "X_test = test_df.values\n",
    "\n",
    "print(f'X shape: {X.shape}')\n",
    "print(f'y shape: {y.shape}')\n",
    "print(f'X_test shape: {X_test.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-02T19:53:31.187838Z",
     "start_time": "2026-01-02T19:53:29.014697Z"
    }
   },
   "outputs": [],
   "source": [
    "# ÐÐ¾Ñ€Ð¼Ð°Ð»Ð¸Ð·Ð°Ñ†Ð¸Ñ [0, 255] -> [0, 1]\n",
    "X = X / 255.0\n",
    "X_test = X_test / 255.0\n",
    "\n",
    "# Reshape Ð´Ð»Ñ CNN: (N, C, H, W)\n",
    "X = X.reshape(-1, 1, 28, 28)\n",
    "X_test = X_test.reshape(-1, 1, 28, 28)\n",
    "\n",
    "print(f'X shape after reshape: {X.shape}')\n",
    "print(f'X_test shape after reshape: {X_test.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-02T19:53:37.105801Z",
     "start_time": "2026-01-02T19:53:34.939631Z"
    }
   },
   "outputs": [],
   "source": [
    "# Train/Validation split\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X, y, test_size=0.1, random_state=RANDOM_SEED, stratify=y\n",
    ")\n",
    "\n",
    "print(f'Train: {X_train.shape}')\n",
    "print(f'Validation: {X_val.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-02T19:53:43.454867Z",
     "start_time": "2026-01-02T19:53:42.102950Z"
    }
   },
   "outputs": [],
   "source": [
    "# Ð¡Ð¾Ð·Ð´Ð°Ð½Ð¸Ðµ PyTorch DataLoader\n",
    "X_train_tensor = torch.FloatTensor(X_train)\n",
    "y_train_tensor = torch.LongTensor(y_train)\n",
    "X_val_tensor = torch.FloatTensor(X_val)\n",
    "y_val_tensor = torch.LongTensor(y_val)\n",
    "X_test_tensor = torch.FloatTensor(X_test)\n",
    "\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "val_dataset = TensorDataset(X_val_tensor, y_val_tensor)\n",
    "test_dataset = TensorDataset(X_test_tensor)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. CNN ÐœÐ¾Ð´ÐµÐ»ÑŒ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-02T19:54:05.372974Z",
     "start_time": "2026-01-02T19:54:05.365001Z"
    }
   },
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        \n",
    "        # Ð¡Ð²Ñ‘Ñ€Ñ‚Ð¾Ñ‡Ð½Ñ‹Ðµ ÑÐ»Ð¾Ð¸\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
    "        \n",
    "        # Batch Normalization\n",
    "        self.bn1 = nn.BatchNorm2d(32)\n",
    "        self.bn2 = nn.BatchNorm2d(64)\n",
    "        self.bn3 = nn.BatchNorm2d(128)\n",
    "        \n",
    "        # Pooling Ð¸ Dropout\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.dropout1 = nn.Dropout(0.25)\n",
    "        self.dropout2 = nn.Dropout(0.5)\n",
    "        \n",
    "        # ÐŸÐ¾Ð»Ð½Ð¾ÑÐ²ÑÐ·Ð½Ñ‹Ðµ ÑÐ»Ð¾Ð¸\n",
    "        # ÐŸÐ¾ÑÐ»Ðµ 3 max pooling: 28 -> 14 -> 7 -> 3\n",
    "        self.fc1 = nn.Linear(128 * 3 * 3, 256)\n",
    "        self.fc2 = nn.Linear(256, 10)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Block 1\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.pool(x)  # 28 -> 14\n",
    "        x = self.dropout1(x)\n",
    "        \n",
    "        # Block 2\n",
    "        x = self.conv2(x)\n",
    "        x = self.bn2(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.pool(x)  # 14 -> 7\n",
    "        x = self.dropout1(x)\n",
    "        \n",
    "        # Block 3\n",
    "        x = self.conv3(x)\n",
    "        x = self.bn3(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.pool(x)  # 7 -> 3\n",
    "        x = self.dropout1(x)\n",
    "        \n",
    "        # Flatten\n",
    "        x = x.view(x.size(0), -1)\n",
    "        \n",
    "        # FC layers\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dropout2(x)\n",
    "        x = self.fc2(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-02T19:54:13.300109Z",
     "start_time": "2026-01-02T19:54:12.800185Z"
    }
   },
   "outputs": [],
   "source": [
    "# Ð˜Ð½Ð¸Ñ†Ð¸Ð°Ð»Ð¸Ð·Ð°Ñ†Ð¸Ñ Ð¼Ð¾Ð´ÐµÐ»Ð¸\n",
    "model = CNN().to(device)\n",
    "print(model)\n",
    "\n",
    "# ÐŸÐ¾Ð´ÑÑ‡Ñ‘Ñ‚ Ð¿Ð°Ñ€Ð°Ð¼ÐµÑ‚Ñ€Ð¾Ð²\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f'\\nÐ’ÑÐµÐ³Ð¾ Ð¿Ð°Ñ€Ð°Ð¼ÐµÑ‚Ñ€Ð¾Ð²: {total_params:,}')\n",
    "print(f'ÐžÐ±ÑƒÑ‡Ð°ÐµÐ¼Ñ‹Ñ… Ð¿Ð°Ñ€Ð°Ð¼ÐµÑ‚Ñ€Ð¾Ð²: {trainable_params:,}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-02T19:55:05.942837Z",
     "start_time": "2026-01-02T19:55:05.889788Z"
    }
   },
   "outputs": [],
   "source": [
    "# Loss Ð¸ Optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. ÐžÐ±ÑƒÑ‡ÐµÐ½Ð¸Ðµ Ð¼Ð¾Ð´ÐµÐ»Ð¸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-02T19:55:11.934838Z",
     "start_time": "2026-01-02T19:55:11.924484Z"
    }
   },
   "outputs": [],
   "source": [
    "def train_epoch(model, loader, criterion, optimizer, device):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    for inputs, labels in loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += labels.size(0)\n",
    "        correct += predicted.eq(labels).sum().item()\n",
    "    \n",
    "    return running_loss / len(loader), 100. * correct / total\n",
    "\n",
    "\n",
    "def validate(model, loader, criterion, device):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            \n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += labels.size(0)\n",
    "            correct += predicted.eq(labels).sum().item()\n",
    "    \n",
    "    return running_loss / len(loader), 100. * correct / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-02T19:56:06.558052Z",
     "start_time": "2026-01-02T19:55:17.910424Z"
    }
   },
   "outputs": [],
   "source": [
    "# ÐžÐ±ÑƒÑ‡ÐµÐ½Ð¸Ðµ\n",
    "history = {\n",
    "    'train_loss': [],\n",
    "    'train_acc': [],\n",
    "    'val_loss': [],\n",
    "    'val_acc': []\n",
    "}\n",
    "\n",
    "best_val_acc = 0\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    train_loss, train_acc = train_epoch(model, train_loader, criterion, optimizer, device)\n",
    "    val_loss, val_acc = validate(model, val_loader, criterion, device)\n",
    "    \n",
    "    # Scheduler step\n",
    "    scheduler.step(val_loss)\n",
    "    \n",
    "    # Ð˜ÑÑ‚Ð¾Ñ€Ð¸Ñ\n",
    "    history['train_loss'].append(train_loss)\n",
    "    history['train_acc'].append(train_acc)\n",
    "    history['val_loss'].append(val_loss)\n",
    "    history['val_acc'].append(val_acc)\n",
    "    \n",
    "    # Ð¡Ð¾Ñ…Ñ€Ð°Ð½ÐµÐ½Ð¸Ðµ Ð»ÑƒÑ‡ÑˆÐµÐ¹ Ð¼Ð¾Ð´ÐµÐ»Ð¸\n",
    "    if val_acc > best_val_acc:\n",
    "        best_val_acc = val_acc\n",
    "        torch.save(model.state_dict(), 'best_model.pth')\n",
    "    \n",
    "    print(f'Epoch [{epoch+1}/{EPOCHS}] | '\n",
    "          f'Train Loss: {train_loss:.4f} | Train Acc: {train_acc:.2f}% | '\n",
    "          f'Val Loss: {val_loss:.4f} | Val Acc: {val_acc:.2f}%')\n",
    "\n",
    "print(f'\\nðŸ† Ð›ÑƒÑ‡ÑˆÐ°Ñ Val Accuracy: {best_val_acc:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Ð’Ð¸Ð·ÑƒÐ°Ð»Ð¸Ð·Ð°Ñ†Ð¸Ñ Ñ€ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚Ð¾Ð² Ð¾Ð±ÑƒÑ‡ÐµÐ½Ð¸Ñ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-02T19:56:30.983572Z",
     "start_time": "2026-01-02T19:56:30.591746Z"
    }
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Loss\n",
    "axes[0].plot(history['train_loss'], label='Train Loss', marker='o')\n",
    "axes[0].plot(history['val_loss'], label='Val Loss', marker='o')\n",
    "axes[0].set_xlabel('Epoch')\n",
    "axes[0].set_ylabel('Loss')\n",
    "axes[0].set_title('Loss Ð¿Ð¾ ÑÐ¿Ð¾Ñ…Ð°Ð¼')\n",
    "axes[0].legend()\n",
    "axes[0].grid(True)\n",
    "\n",
    "# Accuracy\n",
    "axes[1].plot(history['train_acc'], label='Train Accuracy', marker='o')\n",
    "axes[1].plot(history['val_acc'], label='Val Accuracy', marker='o')\n",
    "axes[1].set_xlabel('Epoch')\n",
    "axes[1].set_ylabel('Accuracy (%)')\n",
    "axes[1].set_title('Accuracy Ð¿Ð¾ ÑÐ¿Ð¾Ñ…Ð°Ð¼')\n",
    "axes[1].legend()\n",
    "axes[1].grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. ÐÐ½Ð°Ð»Ð¸Ð· Ð¾ÑˆÐ¸Ð±Ð¾Ðº"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-02T19:56:47.791808Z",
     "start_time": "2026-01-02T19:56:47.611482Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "# Ð—Ð°Ð³Ñ€ÑƒÐ·ÐºÐ° Ð»ÑƒÑ‡ÑˆÐµÐ¹ Ð¼Ð¾Ð´ÐµÐ»Ð¸\n",
    "model.load_state_dict(torch.load('best_model.pth'))\n",
    "model.eval()\n",
    "\n",
    "# ÐŸÑ€ÐµÐ´ÑÐºÐ°Ð·Ð°Ð½Ð¸Ñ Ð½Ð° Ð²Ð°Ð»Ð¸Ð´Ð°Ñ†Ð¸Ð¸\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in val_loader:\n",
    "        inputs = inputs.to(device)\n",
    "        outputs = model(inputs)\n",
    "        _, preds = outputs.max(1)\n",
    "        all_preds.extend(preds.cpu().numpy())\n",
    "        all_labels.extend(labels.numpy())\n",
    "\n",
    "all_preds = np.array(all_preds)\n",
    "all_labels = np.array(all_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-02T19:56:53.104673Z",
     "start_time": "2026-01-02T19:56:52.831441Z"
    }
   },
   "outputs": [],
   "source": [
    "# Confusion Matrix\n",
    "cm = confusion_matrix(all_labels, all_preds)\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "            xticklabels=range(10), yticklabels=range(10))\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-02T19:57:02.580825Z",
     "start_time": "2026-01-02T19:57:02.556110Z"
    }
   },
   "outputs": [],
   "source": [
    "# Classification Report\n",
    "print(classification_report(all_labels, all_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-02T19:57:13.799105Z",
     "start_time": "2026-01-02T19:57:13.245514Z"
    }
   },
   "outputs": [],
   "source": [
    "# Ð’Ð¸Ð·ÑƒÐ°Ð»Ð¸Ð·Ð°Ñ†Ð¸Ñ Ð¾ÑˆÐ¸Ð±Ð¾Ñ‡Ð½Ñ‹Ñ… Ð¿Ñ€ÐµÐ´ÑÐºÐ°Ð·Ð°Ð½Ð¸Ð¹\n",
    "errors_idx = np.where(all_preds != all_labels)[0]\n",
    "\n",
    "if len(errors_idx) > 0:\n",
    "    fig, axes = plt.subplots(2, 5, figsize=(12, 5))\n",
    "    \n",
    "    for i, ax in enumerate(axes.flatten()):\n",
    "        if i < len(errors_idx):\n",
    "            idx = errors_idx[i]\n",
    "            image = X_val[idx].reshape(28, 28)\n",
    "            ax.imshow(image, cmap='gray')\n",
    "            ax.set_title(f'True: {all_labels[idx]}, Pred: {all_preds[idx]}', color='red')\n",
    "        ax.axis('off')\n",
    "    \n",
    "    plt.suptitle('ÐŸÑ€Ð¸Ð¼ÐµÑ€Ñ‹ Ð¾ÑˆÐ¸Ð±Ð¾Ñ‡Ð½Ñ‹Ñ… Ð¿Ñ€ÐµÐ´ÑÐºÐ°Ð·Ð°Ð½Ð¸Ð¹', fontsize=14)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print('Ð’ÑÐµ Ð¿Ñ€ÐµÐ´ÑÐºÐ°Ð·Ð°Ð½Ð¸Ñ Ð²ÐµÑ€Ð½Ñ‹Ðµ!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. ÐŸÑ€ÐµÐ´ÑÐºÐ°Ð·Ð°Ð½Ð¸Ñ Ð½Ð° Ñ‚ÐµÑÑ‚Ð¾Ð²Ñ‹Ñ… Ð´Ð°Ð½Ð½Ñ‹Ñ… Ð¸ submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-02T19:58:08.378679Z",
     "start_time": "2026-01-02T19:58:07.444411Z"
    }
   },
   "outputs": [],
   "source": [
    "# ÐŸÑ€ÐµÐ´ÑÐºÐ°Ð·Ð°Ð½Ð¸Ñ\n",
    "model.eval()\n",
    "predictions = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for (inputs,) in test_loader:\n",
    "        inputs = inputs.to(device)\n",
    "        outputs = model(inputs)\n",
    "        _, preds = outputs.max(1)\n",
    "        predictions.extend(preds.cpu().numpy())\n",
    "\n",
    "predictions = np.array(predictions)\n",
    "print(f'Ð’ÑÐµÐ³Ð¾ Ð¿Ñ€ÐµÐ´ÑÐºÐ°Ð·Ð°Ð½Ð¸Ð¹: {len(predictions)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-02T19:58:20.102823Z",
     "start_time": "2026-01-02T19:58:19.564501Z"
    }
   },
   "outputs": [],
   "source": [
    "# Ð’Ð¸Ð·ÑƒÐ°Ð»Ð¸Ð·Ð°Ñ†Ð¸Ñ Ð¿Ñ€ÐµÐ´ÑÐºÐ°Ð·Ð°Ð½Ð¸Ð¹\n",
    "fig, axes = plt.subplots(2, 5, figsize=(12, 5))\n",
    "\n",
    "random_test_indices = np.random.choice(len(X_test), 10, replace=False)\n",
    "\n",
    "for i, ax in enumerate(axes.flatten()):\n",
    "    idx = random_test_indices[i]\n",
    "    image = X_test[idx].reshape(28, 28)\n",
    "    ax.imshow(image, cmap='gray')\n",
    "    ax.set_title(f'Pred: {predictions[idx]}')\n",
    "    ax.axis('off')\n",
    "\n",
    "plt.suptitle('ÐŸÑ€Ð¸Ð¼ÐµÑ€Ñ‹ Ð¿Ñ€ÐµÐ´ÑÐºÐ°Ð·Ð°Ð½Ð¸Ð¹ Ð½Ð° Ñ‚ÐµÑÑ‚Ð¾Ð²Ñ‹Ñ… Ð´Ð°Ð½Ð½Ñ‹Ñ…', fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-02T19:58:44.801266Z",
     "start_time": "2026-01-02T19:58:44.753275Z"
    }
   },
   "outputs": [],
   "source": [
    "# Ð¡Ð¾Ð·Ð´Ð°Ð½Ð¸Ðµ submission Ñ„Ð°Ð¹Ð»Ð°\n",
    "submission = pd.DataFrame({\n",
    "    'ImageId': range(1, len(predictions) + 1),\n",
    "    'Label': predictions\n",
    "})\n",
    "\n",
    "submission.to_csv('submission.csv', index=False)\n",
    "print('âœ… submission.csv ÑÐ¾Ð·Ð´Ð°Ð½!')\n",
    "submission.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-02T19:58:53.365436Z",
     "start_time": "2026-01-02T19:58:53.081752Z"
    }
   },
   "outputs": [],
   "source": [
    "# ÐŸÑ€Ð¾Ð²ÐµÑ€ÐºÐ° submission\n",
    "print(f'Ð Ð°Ð·Ð¼ÐµÑ€ submission: {submission.shape}')\n",
    "print(f'\\nÐ Ð°ÑÐ¿Ñ€ÐµÐ´ÐµÐ»ÐµÐ½Ð¸Ðµ Ð¿Ñ€ÐµÐ´ÑÐºÐ°Ð·Ð°Ð½Ð½Ñ‹Ñ… ÐºÐ»Ð°ÑÑÐ¾Ð²:')\n",
    "print(submission['Label'].value_counts().sort_index())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Ð˜Ñ‚Ð¾Ð³Ð¸ Ð¸ Ð´Ð°Ð»ÑŒÐ½ÐµÐ¹ÑˆÐ¸Ðµ ÑƒÐ»ÑƒÑ‡ÑˆÐµÐ½Ð¸Ñ\n",
    "\n",
    "### Ð§Ñ‚Ð¾ ÑÐ´ÐµÐ»Ð°Ð½Ð¾:\n",
    "- âœ… EDA Ð¸ Ð²Ð¸Ð·ÑƒÐ°Ð»Ð¸Ð·Ð°Ñ†Ð¸Ñ Ð´Ð°Ð½Ð½Ñ‹Ñ…\n",
    "- âœ… CNN Ð¼Ð¾Ð´ÐµÐ»ÑŒ Ñ BatchNorm Ð¸ Dropout\n",
    "- âœ… ÐžÐ±ÑƒÑ‡ÐµÐ½Ð¸Ðµ Ñ learning rate scheduler\n",
    "- âœ… ÐÐ½Ð°Ð»Ð¸Ð· Ð¾ÑˆÐ¸Ð±Ð¾Ðº (Confusion Matrix)\n",
    "- âœ… Ð¡Ð¾Ð·Ð´Ð°Ð½Ð¸Ðµ submission Ñ„Ð°Ð¹Ð»Ð°\n",
    "\n",
    "### Ð˜Ð´ÐµÐ¸ Ð´Ð»Ñ ÑƒÐ»ÑƒÑ‡ÑˆÐµÐ½Ð¸Ñ:\n",
    "1. **Data Augmentation** - Ð¿Ð¾Ð²Ð¾Ñ€Ð¾Ñ‚Ñ‹, ÑÐ´Ð²Ð¸Ð³Ð¸, Ð¼Ð°ÑÑˆÑ‚Ð°Ð±Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð¸Ðµ\n",
    "2. **Ð‘Ð¾Ð»ÐµÐµ Ð³Ð»ÑƒÐ±Ð¾ÐºÐ°Ñ Ð°Ñ€Ñ…Ð¸Ñ‚ÐµÐºÑ‚ÑƒÑ€Ð°** - ResNet, EfficientNet\n",
    "3. **Ensemble** - Ð¾Ð±ÑŠÐµÐ´Ð¸Ð½ÐµÐ½Ð¸Ðµ Ð½ÐµÑÐºÐ¾Ð»ÑŒÐºÐ¸Ñ… Ð¼Ð¾Ð´ÐµÐ»ÐµÐ¹\n",
    "4. **Cross-Validation** - Ð±Ð¾Ð»ÐµÐµ Ð½Ð°Ð´Ñ‘Ð¶Ð½Ð°Ñ Ð¾Ñ†ÐµÐ½ÐºÐ°\n",
    "5. **Pseudo-labeling** - Ð¸ÑÐ¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ð½Ð¸Ðµ Ñ‚ÐµÑÑ‚Ð¾Ð²Ñ‹Ñ… Ð´Ð°Ð½Ð½Ñ‹Ñ…\n",
    "6. **Hyperparameter tuning** - Optuna, Ray Tune"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
